{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "__DEBUG__= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imgread_rgb(path):\n",
    "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_many(imgs,titles,shape,cmaps=None,figsize=(24,9)):\n",
    "    \n",
    "    assert len(imgs) == len(titles) and len(imgs) == shape[0]*shape[1]\n",
    "    \n",
    "    fig, axes = plt.subplots(shape[0],shape[1],figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        axes[i].imshow(imgs[i],cmap=cmaps[i] if cmaps is not None else None)\n",
    "        axes[i].set_title(titles[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_polygon(img,pts,color=[255,0,0],thickness=5,isClosed=True):\n",
    "    n = len(pts)\n",
    "    try:\n",
    "        for i in range(n-1):\n",
    "            cv2.line(img,pts[i],pts[i+1],color,thickness) \n",
    "\n",
    "        if isClosed == True:\n",
    "            cv2.line(img,pts[n-1],pts[(0)],color,thickness)\n",
    "    except :\n",
    "        print(\"Error trying to draw line {} {}\".format(pts[i],pts[i+1]))\n",
    "        raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlay_polygon(img,pts,alpha=1.,beta=1.,gamma=0.):\n",
    "    overlay = np.zeros_like(img)    \n",
    "    draw_polygon(overlay,pts)\n",
    "    return cv2.addWeighted(img,alpha,overlay,beta,gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for performing camera calibraation\n",
    "\n",
    "def calibrate_camera(calib_img_dir,nb_x_corners,nb_y_corners):\n",
    "    \n",
    "    calib_img_paths = glob(calib_img_dir+'*.jpg')\n",
    "\n",
    "    # Object points are 3-D integral coordinates of all internal corners\n",
    "    # in a Chessboard image. The z coordinates are all zero.\n",
    "\n",
    "    # The object points matrix has as many columns as there are x positions\n",
    "    # and as many rows as there are y positions.\n",
    "\n",
    "    x_coords,y_coords = np.meshgrid(range(nb_x_corners),range(nb_y_corners))\n",
    "    z_coords = np.zeros(shape=[nb_y_corners,nb_x_corners])\n",
    "\n",
    "    obj_points = np.dstack((x_coords,y_coords,z_coords))\n",
    "\n",
    "    # Reshape the matrx of coordinates in to a list that has all coordinates\n",
    "    # from left to right and top to bottom.\n",
    "    obj_points = obj_points.reshape([-1,3])\n",
    "\n",
    "    obj_points_list = []\n",
    "    img_points_list = []\n",
    "\n",
    "    detected = 0\n",
    "\n",
    "    for path in tqdm(calib_img_paths):\n",
    "        img = imgread_rgb(path)\n",
    "        grey = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(grey,(nb_x_corners,nb_y_corners))\n",
    "\n",
    "        if ret == True:\n",
    "            if __DEBUG__:\n",
    "                cv2.drawChessboardCorners(img,(nb_x_corners,nb_y_corners),corners,ret)\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "\n",
    "            obj_points_list.append(obj_points)\n",
    "            img_points_list.append(corners)\n",
    "\n",
    "            detected += 1\n",
    "            \n",
    "    # Reshape object points and image points as required by the new OpenCV interface\n",
    "    obj_points_matrix = np.array(obj_points_list).reshape([detected,-1,3])\n",
    "    img_points_matrix = np.array(img_points_list).reshape([detected,-1,2])\n",
    "    \n",
    "    # Perform actual calibration using our object points and \n",
    "    # image points found above.\n",
    "    test_img = imgread_rgb('camera_cal/calibration1.jpg')\n",
    "    retval, cameraMatrix, distCoeffs, rvecs, tvecs =\\\n",
    "    cv2.calibrateCamera(obj_points_matrix.astype(np.float32),\n",
    "                        img_points_matrix.astype(np.float32),\n",
    "                        (test_img.shape[1],test_img.shape[0]),\n",
    "                        None,\n",
    "                        None)\n",
    "    \n",
    "    return retval, cameraMatrix, distCoeffs, rvecs, tvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform camera calibration.\n",
    "\n",
    "calib_img_dir = './camera_cal/'\n",
    "\n",
    "# Number of internal corners in the calibration images.\n",
    "# Obtained by manual inspection.\n",
    "nb_x_corners = 9\n",
    "nb_y_corners = 6\n",
    "\n",
    "retval, cameraMatrix, distCoeffs, rvecs, tvecs = calibrate_camera(calib_img_dir,nb_x_corners,nb_y_corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_thresholds():\n",
    "    return {'x':(50,180), 'y':(50,180), 'mag':(80,150),'ang':(0.85,1.0),'s':(170,255),'l':(0,20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_abs_sobel_mask(img, orient='x', kernel=3, thresh=(0,255)):\n",
    "    \n",
    "    grey  = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.abs(cv2.Sobel(grey,cv2.CV_64F,1,0,None,kernel))\n",
    "    elif orient == 'y':\n",
    "        abs_sobel = np.abs(cv2.Sobel(grey,cv2.CV_64F,0,1,None,kernel))\n",
    "    else:\n",
    "        raise Exception(\"Invalid orientation {}\".format(x))\n",
    "     \n",
    "    scaled_abs_sobel = (255. * abs_sobel / np.max(abs_sobel)).astype(np.uint8)\n",
    "    \n",
    "    binary_mask = np.logical_and(abs_sobel >= thresh[0], abs_sobel <= thresh[1] )\n",
    "    \n",
    "    return binary_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mag_sobel_mask(img, kernel=3, mag_thresh=(0,255)):\n",
    "    \n",
    "    grey = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    abs_sobel_x = np.abs(cv2.Sobel(grey,cv2.CV_64F,1,0,None,kernel))\n",
    "    abs_soble_y = np.abs(cv2.Sobel(grey,cv2.CV_64F,0,1,None,kernel))\n",
    "    abs_sobel_mag = np.sqrt(abs_sobel_x**2+abs_soble_y**2)\n",
    "    \n",
    "    scaled_abs_sobel_mag = (abs_sobel_mag * 255.0 / np.max(abs_sobel_mag)).astype(np.uint8)\n",
    "    \n",
    "    binary_mask = np.logical_and(scaled_abs_sobel_mag >= mag_thresh[0], \n",
    "                                 scaled_abs_sobel_mag <= mag_thresh[1])\n",
    "    \n",
    "    return binary_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ang_sobel_mask(img, kernel=3, ang_thresh=(0,np.pi/2.)):\n",
    "    \n",
    "    grey = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    abs_sobel_x = np.abs(cv2.Sobel(grey,cv2.CV_64F,1,0,None,kernel))\n",
    "    abs_soble_y = np.abs(cv2.Sobel(grey,cv2.CV_64F,0,1,None,kernel))\n",
    "    \n",
    "    \n",
    "    abs_sobel_angle = np.arctan2(abs_soble_y,abs_sobel_x)\n",
    "    \n",
    "    \n",
    "    binary_mask = np.logical_and(abs_sobel_angle >= ang_thresh[0], \n",
    "                                 abs_sobel_angle <= ang_thresh[1])\n",
    "    \n",
    "    return binary_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sobel_masks(img,mask_names=['x','y','mag','ang'],threshold_params=None):\n",
    "   \n",
    "    masks = []\n",
    "    if 'x' in mask_names:\n",
    "        x_mask = get_abs_sobel_mask(img,orient='x',kernel=3,thresh=threshold_params['x'])\n",
    "        masks.append(x_mask)\n",
    "    \n",
    "    if 'y' in mask_names:\n",
    "        y_mask = get_abs_sobel_mask(img,orient='y',kernel=3,thresh=threshold_params['y'])\n",
    "        masks.append(y_mask)\n",
    "        \n",
    "    if 'mag' in mask_names:\n",
    "        mag_mask = get_mag_sobel_mask(img,kernel=3,mag_thresh=threshold_params['mag'])\n",
    "        masks.append(mag_mask)\n",
    "        \n",
    "    if 'ang' in mask_names:\n",
    "        ang_mask = get_ang_sobel_mask(img,kernel=15,ang_thresh=threshold_params['ang'])\n",
    "        masks.append(ang_mask)\n",
    "    \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_channel_mask_fn(chan_name:str):\n",
    "    ''' \n",
    "    Returns a function that can be used to generate a binary mask from an RGB or HSV image.\n",
    "    The function returned s configured based on the channel_name passed here.\n",
    "    if the chan_name argument is 'h', 's' or 'v', automatic olorspace conversion would be done\n",
    "    by the returned function.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    name_to_index = { 'b':2, 'g':1, 'r':0, 'h':0, 'l':1, 's':2}\n",
    "    \n",
    "    if chan_name not in name_to_index.keys():\n",
    "        raise Exception('{} chan_name is not a valid chanel name'.format(chan_name))\n",
    "        \n",
    "    def no_conversion(img):\n",
    "        return img\n",
    "        \n",
    "    color_scheme_converson_fn = lambda img: no_conversion(img) if chan_name in ['b','g','r'] else cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    def _f(img,thresh=(0,255)):\n",
    "        '''\n",
    "        img: RGB or HSV image.Performs automatic colorspace conversion if needed.\n",
    "        '''\n",
    "        img_converted = color_scheme_converson_fn(img)\n",
    "        channel = img_converted[:,:,name_to_index[chan_name]]\n",
    "        binary_mask = (np.logical_and(channel >= thresh[0], channel <= thresh[1])).astype(np.uint8)\n",
    "    \n",
    "        return binary_mask\n",
    "    \n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Mask\n",
    "This function combines different binary masks to isolate lane pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lane_mask(img_rgb,thresh_params):\n",
    "    mag_mask,ang_mask = get_sobel_masks(img_rgb,['mag','ang'],thresh_params)\n",
    "    \n",
    "    get_s_mask = get_channel_mask_fn('s')\n",
    "    get_l_mask = get_channel_mask_fn('l')\n",
    "    \n",
    "    s_mask = get_s_mask(img_rgb,thresh=thresh_params['s'])\n",
    "    l_mask = get_l_mask(img_rgb,thresh=thresh_params['l'])\n",
    "    \n",
    "    \n",
    "    mag_s_mask = mag_mask | s_mask\n",
    "    ang_s_mask = ang_mask & s_mask\n",
    "    mag_ang_s_mask = mag_s_mask | ang_s_mask\n",
    "    mag_ang_s_l_mask = mag_ang_s_mask & (~l_mask)\n",
    "    \n",
    "    return mag_ang_s_l_mask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perpective Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_persprective_transforms(src_points, dst_points):\n",
    "    M = cv2.getPerspectiveTransform(np.float32(src_points),np.float32(dst_points))\n",
    "    Minv = cv2.getPerspectiveTransform(np.float32(dst_points),np.float32(src_points))\n",
    "    \n",
    "    return M,Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(img,M):\n",
    "    img_size = img_size = (img.shape[1],img.shape[0])\n",
    "    return cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference image.\n",
    "perspective_ref_img_path = 'test_images/straight_lines1.jpg'\n",
    "# Points seleted by manual inspetion of reference path.\n",
    "perspective_src_points = [(203,720),(1099,720),(707,463),(580,463)]\n",
    "perspective_dst_points = [(203,720),(1099,720),(1099,0),(203,0)]\n",
    "\n",
    "\n",
    "# Find and apply perspective transform.\n",
    "M,Minv = get_persprective_transforms(perspective_src_points,perspective_dst_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Search and Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lanes(binary_image,prev_fits = None, debug=False):\n",
    "\n",
    "    if debug == True:\n",
    "        debug_img = np.dstack((binary_image,binary_image,binary_image)) * 255\n",
    "    \n",
    "    # Windowed search params.\n",
    "    nb_windows = 9\n",
    "    window_half_width = 100\n",
    "    \n",
    "    # nonzero() returns row and column indices\n",
    "    # convert to x and y coordinates.\n",
    "    nonzero_y = np.nonzero(binary_image)[0]\n",
    "    nonzero_x = np.nonzero(binary_image)[1]\n",
    "    \n",
    "    recenter_threshold = 50\n",
    "\n",
    "    \n",
    "    def find_lane_bases():\n",
    "        # Find hot columns in the lower half of the image.\n",
    "        mid_row = np.int(binary_image.shape[0] / 2)\n",
    "        histogram = np.sum(binary_image[mid_row:,:],axis=0)\n",
    "\n",
    "        mid_col = np.int(histogram.shape[0] / 2)\n",
    "\n",
    "        # Return indices of hottest columns in the left and right halves. \n",
    "        return np.argmax(histogram[:mid_col]), mid_col + np.argmax(histogram[mid_col:])\n",
    "\n",
    "    \n",
    "    def search_lane(x_center,hot_pixel_color=None):\n",
    "        window_height = np.int(binary_image.shape[0]/nb_windows)\n",
    "        \n",
    "        search_window_corners = []\n",
    "        lane_x_coordintes = []\n",
    "        lane_y_coordintes = []\n",
    "        \n",
    "        for i in range(nb_windows):\n",
    "            window_x_lo = x_center - window_half_width\n",
    "            window_x_hi = x_center + window_half_width\n",
    "            \n",
    "            # Height is number of rows in image matrix and y coordinate increases\n",
    "            # from bottom to top so y_lo is the numerically lower, top extent of \n",
    "            # the window and y_hi is the numerically higher, bottom extent of the\n",
    "            # window.\n",
    "            window_y_lo = binary_image.shape[0] - (i+1)*window_height\n",
    "            window_y_hi = window_y_lo + window_height\n",
    "            \n",
    "            # Add window coordintes to list.\n",
    "            search_window_corners.append([(window_x_lo,window_y_lo),(window_x_hi,window_y_hi)])\n",
    "            \n",
    "            # Find 'ON' pixels that lie within the current window.\n",
    "            is_on = ( (nonzero_x >= window_x_lo) & (nonzero_x <= window_x_hi) ) &\\\n",
    "                    ( (nonzero_y >= window_y_lo) & (nonzero_y <= window_y_hi) )\n",
    "                \n",
    "            on_x = nonzero_x[is_on]\n",
    "            on_y = nonzero_y[is_on]\n",
    "            \n",
    "            if debug == True:\n",
    "                debug_img[on_y,on_x,:] = hot_pixel_color\n",
    "                cv2.rectangle(debug_img,(window_x_lo,window_y_lo),(window_x_hi,window_y_hi),[0,0,255],5)\n",
    "            \n",
    "            lane_x_coordintes.append(on_x)\n",
    "            lane_y_coordintes.append(on_y)\n",
    "            \n",
    "            # If 'ON' pixel count is above threshold, recenter the window (horizontally).\n",
    "            if np.sum(is_on) >= recenter_threshold:\n",
    "                x_center = np.int(np.mean(on_x))\n",
    "\n",
    "            \n",
    "        \n",
    "        lane_x_coordintes = np.concatenate(lane_x_coordintes)\n",
    "        lane_y_coordintes = np.concatenate(lane_y_coordintes)\n",
    "        \n",
    "        return search_window_corners,(lane_x_coordintes,lane_y_coordintes)\n",
    "    \n",
    "    \n",
    "    def probe_nearby(prev_fit,hot_pixel_color=None):\n",
    "        \n",
    "        # We already have pairs of all ON pixel coordinates\n",
    "        # in nonzero_y[i] and nonzero_x[i]. For every nonzero_y[i]\n",
    "        # get a the predicted value x_predicted[i]. \n",
    "        x_predicted = prev_fit[0] * nonzero_y**2 + prev_fit[1] * nonzero_y + prev_fit[2]\n",
    "        \n",
    "        # For every nononzero_x[i] check if it's close enough to our predicted \n",
    "        # x_predicted[i]\n",
    "        is_x_in_vicinity = (nonzero_x >= x_predicted - window_half_width) &\\\n",
    "                           (nonzero_x <= x_predicted + window_half_width)\n",
    "\n",
    "        lane_x_coordintes = nonzero_x[is_x_in_vicinity]\n",
    "        lane_y_coordintes = nonzero_y[is_x_in_vicinity]\n",
    "        \n",
    "        return lane_x_coordintes, lane_y_coordintes\n",
    "        \n",
    "               \n",
    "    \n",
    "    # Search using histogram and sliding windows if prior ane position is not known.\n",
    "    if prev_fits == None:\n",
    "        if __DEBUG__ == True:\n",
    "            print(\"Performing sliding window search.\")\n",
    "            \n",
    "        left_lane_base_x, right_lane_base_x = find_lane_bases()\n",
    "        \n",
    "        left_lane_info  = search_lane(left_lane_base_x,hot_pixel_color=[255,0,0])\n",
    "        right_lane_info = search_lane(right_lane_base_x,hot_pixel_color=[0,255,0])\n",
    "        \n",
    "    else:\n",
    "        if __DEBUG__ == True:\n",
    "            print(\"Performing targeted search.\")\n",
    "            \n",
    "        left_lane_coords  = probe_nearby(prev_fits[0],hot_pixel_color=[255,0,0])\n",
    "        right_lane_coords = probe_nearby(prev_fits[1],hot_pixel_color=[0,255,0])\n",
    "        \n",
    "        # Return empty list of window corners alongwith lane coordinates.\n",
    "        left_lane_info  = ([],left_lane_coords )\n",
    "        right_lane_info = ([],right_lane_coords)\n",
    "    \n",
    "    if debug == True:\n",
    "        plt.imshow(debug_img)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return left_lane_info,right_lane_info\n",
    "                \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_poly_to_lane(x_pts,y_pts):\n",
    "    return np.polyfit(y_pts,x_pts,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_qudratic(coeffs,pts):\n",
    "    return (coeffs[0] * pts**2 + coeffs[1] * pts + coeffs[2]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The height, width calculations below depend on the order in which target points for perspective transform have been defined. In our case the points are defined as **Bottom left -> Bottom right -> Top right -> Top left**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lane_width = abs(perspective_dst_points[0][0] - perspective_dst_points[1][0])\n",
    "lane_height = abs(perspective_dst_points[0][1] - perspective_dst_points[3][1])\n",
    "ym_per_pix = 30/lane_height # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/lane_width # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_curvature(xs_pixel,ys_pixel,at_pixel): \n",
    "    xs = xm_per_pix * xs_pixel\n",
    "    ys = ym_per_pix * ys_pixel\n",
    "    at = ym_per_pix * at_pixel\n",
    "    \n",
    "    poly = np.polyfit(ys,xs,2)\n",
    "    curvature =  ((1 + (2*poly[0]*at + poly[1]) ** 2) ** 1.5) / abs(2*poly[0])\n",
    "    return curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_displacement(base_left_x,base_right_x, base_center_x):\n",
    "    center_x  = (base_left_x+base_right_x)/2.0\n",
    "    displacement = abs(center_x-base_center_x) \n",
    "    \n",
    "    return displacement * xm_per_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FitsHist: \n",
    "    def __init__(self,sz=5):\n",
    "        self.history = deque(maxlen=sz)\n",
    "        \n",
    "    def is_empty(self):\n",
    "        return len(self.history) is 0\n",
    "    \n",
    "    def is_not_full(self):\n",
    "        return len(self.history) < maxlen(self.history)\n",
    "    \n",
    "    def get_len(self):\n",
    "        return len(self.history)\n",
    "    \n",
    "    def add_fit_info(self,polyfits,radii):\n",
    "        self.history.extend([[polyfits,radii]])\n",
    "        \n",
    "    def get_all_fit_info(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def get_prev_fit_info(self):\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        \n",
    "        return self.history[-1]\n",
    "    \n",
    "    def popleft(self):\n",
    "        return self.history.popleft()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_hist = None\n",
    "\n",
    "def clr_hist():\n",
    "    fit_hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lanes(img):\n",
    "    \n",
    "    def check_valid(left_lane_info,right_lane_info):\n",
    "        _, left_lane_candidates  = left_lane_info\n",
    "        _,right_lane_candidates  = right_lane_info\n",
    "\n",
    "        valid_left_found  = (len(left_lane_candidates[0]) > 0) &\\\n",
    "                            (len(left_lane_candidates[0]) == len(left_lane_candidates[1]))\n",
    "        \n",
    "        valid_right_found = (len(right_lane_candidates[0]) > 0) &\\\n",
    "                            (len(right_lane_candidates[0]) == len(right_lane_candidates[1]))\n",
    "            \n",
    "        return valid_left_found,valid_right_found\n",
    "    \n",
    "    def get_fits(left_lane_info,right_lane_info):\n",
    "        if left_lane_info is not None:\n",
    "            _, left_lane_candidates  = left_lane_info\n",
    "            left_fit = fit_poly_to_lane(*left_lane_candidates)\n",
    "        else:\n",
    "            left_fit = None\n",
    "            \n",
    "        if right_lane_info is not None:\n",
    "            _,right_lane_candidates  = right_lane_info\n",
    "            right_fit = fit_poly_to_lane(*right_lane_candidates)\n",
    "        else:\n",
    "            right_fit = None\n",
    "        \n",
    "        return  left_fit,right_fit\n",
    "    \n",
    "    def get_raw_radii(left_lane_info,right_lane_info,y_bottom):\n",
    "        \n",
    "        radius_left, radius_right = None, None\n",
    "        \n",
    "        if left_lane_info is not None:\n",
    "            _,(left_lane_x,left_lane_y) = left_lane_info\n",
    "            radius_left  = find_curvature(left_lane_x,left_lane_y,y_bottom)\n",
    "        \n",
    "        if right_lane_info is not None:\n",
    "            _,(right_lane_x,right_lane_y) = right_lane_info\n",
    "            radius_right = find_curvature(right_lane_x,right_lane_y,y_bottom)\n",
    "            \n",
    "        return (radius_left,radius_right)\n",
    "    \n",
    "    \n",
    "    def get_smoothed_predictions(history,ys):\n",
    "        xs_left, xs_right = np.zeros_like(ys), np.zeros_like(ys)\n",
    "        \n",
    "        all_fit_infos = history.get_all_fit_info()\n",
    "        for fit_info in all_fit_infos:\n",
    "            fits = fit_info[0]\n",
    "            xs_left += eval_qudratic(fits[0],ys)\n",
    "            xs_right += eval_qudratic(fits[1],ys)\n",
    "       \n",
    "        xs_left  = (xs_left / len(all_fit_infos)).astype(np.int32)\n",
    "        xs_right = (xs_right / len(all_fit_infos)).astype(np.int32)\n",
    "        \n",
    "        return xs_left,xs_right\n",
    "    \n",
    "    def get_smoothed_radius(history):\n",
    "        all_fit_infos = history.get_all_fit_info()\n",
    "        \n",
    "        radius_left, radius_right = 0.0, 0.0\n",
    "        for fit_info in all_fit_infos:\n",
    "            radii = fit_info[1]\n",
    "            \n",
    "            radius_left += radii[0]\n",
    "            radius_right += radii[1]\n",
    "            \n",
    "        radius_left = radius_left / len(all_fit_infos)\n",
    "        radius_right = radius_right/ len(all_fit_infos)\n",
    "        \n",
    "        return (radius_left+radius_right)/2.\n",
    "        \n",
    "        \n",
    "    \n",
    "    def outlier_detect(frame,history,left_poly,right_poly):\n",
    "        ys  = np.array(range(frame.shape[0]),dtype=np.int32)\n",
    "        \n",
    "        left_xs  = eval_qudratic(left_poly,ys)\n",
    "        right_xs = eval_qudratic(right_poly,ys)\n",
    "        \n",
    "        lane_width = np.abs(left_xs-right_xs)\n",
    "        \n",
    "        # Get minimum and maximum widths in meters.\n",
    "        min_width = np.min(lane_width) * xm_per_pix\n",
    "        max_width = np.max(lane_width) * xm_per_pix\n",
    "        \n",
    "        if min_width < 3 or max_width > 4:\n",
    "            return True\n",
    "        \n",
    "        hist_left_xs, hist_right_xs = get_smoothed_predictions(history,ys)\n",
    "        \n",
    "        deviations_left = np.abs(left_xs-hist_left_xs)\n",
    "        deviations_right = np.abs(right_xs-hist_right_xs)\n",
    "        \n",
    "        left_max_dev = np.max(deviations_left)\n",
    "        right_max_dev = np.max(deviations_right)\n",
    "        \n",
    "        if  left_max_dev > 100 or right_max_dev > 100:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "\n",
    "   \n",
    "    # Apply camera distortion correction.\n",
    "    undistorted = cv2.undistort(img,cameraMatrix,distCoeffs)\n",
    "    \n",
    "    # Extract mask with lane pixels.\n",
    "    thresh_params = get_thresholds()\n",
    "    binary_image = get_lane_mask(undistorted,thresh_params)\n",
    "    \n",
    "    # Switch to bird's eye view of the lanes.\n",
    "    perspective_corrected = warp(binary_image,M) \n",
    "    \n",
    "    # Y coordinate at the bottom of the frame.\n",
    "    y_bottom = perspective_corrected.shape[0]-1\n",
    "    \n",
    "    # Get coordinates of potential lane pixels.\n",
    "    global fit_hist\n",
    "    \n",
    "    if fit_hist is None or fit_hist.is_empty():\n",
    "        if fit_hist == None:\n",
    "            fit_hist = FitsHist()\n",
    "        \n",
    "        # Get lane pixels.\n",
    "        lane_infos = find_lanes(perspective_corrected,None)\n",
    "    \n",
    "        valid_left_found, valid_right_found = check_valid(*lane_infos)\n",
    "        if valid_left_found == False or valid_right_found == False:\n",
    "            raise Exception(\"No lane history exists and failed to identify new lanes.\")\n",
    "        \n",
    "        # Fit a poynomial to lane pixels.\n",
    "        left_poly, right_poly = get_fits(*lane_infos)\n",
    "        \n",
    "        # Calculate radii from raw data\n",
    "        radii = get_raw_radii(*lane_infos,y_bottom)\n",
    "        \n",
    "        # Add new fits to history.\n",
    "        fit_hist.add_fit_info((left_poly, right_poly),radii)\n",
    "    \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        prev_fit_info = fit_hist.get_prev_fit_info()\n",
    "        prev_polys = prev_fit_info[0]\n",
    "        prev_radii = prev_fit_info[1] \n",
    "        \n",
    "        assert prev_fit_info is not None and prev_polys is not None\n",
    "        \n",
    "\n",
    "        lane_infos = find_lanes(perspective_corrected,prev_polys)\n",
    "        valid_left_found, valid_right_found = check_valid(*lane_infos)\n",
    "        \n",
    "        # Fit polynomials to left and right lane's coordinates.\n",
    "        # Calculate radii from raw data\n",
    "        \n",
    "        if valid_left_found and valid_right_found:\n",
    "            left_poly,right_poly = get_fits(*lane_infos)\n",
    "            left_radius,right_radius = get_raw_radii(*lane_infos,y_bottom)\n",
    "        \n",
    "        elif valid_left_found:\n",
    "            if __DEBUG__ == True:\n",
    "                print(\"Reusing right lane info from history.\")\n",
    "            left_poly,_ = get_fits(lane_infos[0],None)\n",
    "            right_poly  = prev_polys[1]\n",
    "            \n",
    "            left_radius,_ = get_raw_radii(lane_infos[0],None)\n",
    "            right_radius  = prev_radii[1]\n",
    "\n",
    "        elif valid_right_found:\n",
    "            if __DEBUG__ == True:\n",
    "                print(\"Reusing left lane fit from history.\")\n",
    "            _,right_poly = get_fits(None,lane_infos[1])\n",
    "            left_poly  = prev_polys[0]\n",
    "            \n",
    "            _,right_radius = get_raw_radii(None,lane_infos[1])\n",
    "            left_radius = prev_radii[0]\n",
    "\n",
    "        else:\n",
    "            if __DEBUG__ == True:\n",
    "                print(\"Reusing both lane fits from history.\")\n",
    "            left_poly, right_poly = prev_polys\n",
    "            left_radius, right_radius = prev_radii\n",
    "        \n",
    "        # Skip adding outlier fits to history.   \n",
    "        if outlier_detect(perspective_corrected,fit_hist,left_poly,right_poly):\n",
    "            if fit_hist.get_len()<=2:\n",
    "                fit_hist.add_fit_info((left_poly, right_poly), (left_radius, right_radius))\n",
    "            else:\n",
    "                fit_hist.popleft()\n",
    "                if __DEBUG__ == True:\n",
    "                    print(\"Outlier frame dropped!\")\n",
    "        else:\n",
    "            fit_hist.add_fit_info((left_poly, right_poly), (left_radius, right_radius))\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Generate y coordinates for the entire frame.\n",
    "    ys = np.array(range(1,perspective_corrected.shape[0]),dtype=np.int32)\n",
    "    \n",
    "    # Get smoothed, predictions for x coordinates of both lanes.\n",
    "    xs_left, xs_right = get_smoothed_predictions(fit_hist,ys)       \n",
    "    \n",
    "    # Combine x, y into points for individual lanes and polygon area\n",
    "    # between the lanes.\n",
    "    left_pts  = [(x,y) for (x,y) in zip(xs_left, ys)]\n",
    "    right_pts = [(x,y) for (x,y) in zip(xs_right,ys)]\n",
    "    all_pts = [pt for pt in left_pts]\n",
    "    all_pts.extend([pt for pt in reversed(right_pts)])\n",
    "    \n",
    "    # Get radius of curvature and estimated displacement of the camera\n",
    "    # from center of the lanes.\n",
    "    x_center = perspective_corrected.shape[1] / 2\n",
    "    base_left_x = xs_left[np.where(ys==y_bottom)[0]][0]\n",
    "    base_right_x = xs_right[np.where(ys==y_bottom)[0]][0]\n",
    "    displacement = get_displacement(base_left_x,base_right_x,x_center)\n",
    "    \n",
    "    radius = get_smoothed_radius(fit_hist)\n",
    "    \n",
    "    # Add radius and displacement to the frame image.\n",
    "    cv2.putText(undistorted,\n",
    "                \"Radius: {:0.2f} m\".format(radius),\n",
    "                (400,650),\n",
    "                cv2.FONT_HERSHEY_PLAIN,\n",
    "                 3.,\n",
    "                [0,255,0],5)\n",
    "\n",
    "    cv2.putText(undistorted,\n",
    "                \"Displacement: {:0.2f} cm\".format(displacement*100),\n",
    "                (400,680),\n",
    "                cv2.FONT_HERSHEY_PLAIN,\n",
    "                 2.5,\n",
    "                [0,255,0],5)\n",
    "    \n",
    "    # Get an RGB copy of the bird's eye view and do all lane drawing\n",
    "    # region hghlighting on this copy.\n",
    "    overlay = np.dstack((perspective_corrected,perspective_corrected,perspective_corrected)) * 255\n",
    "    \n",
    "    cv2.fillPoly(overlay,np.array([all_pts],dtype = np.int32),[255,255,0])\n",
    "    draw_polygon(overlay,left_pts,color=[0,255,0],isClosed=False,thickness=30)\n",
    "    draw_polygon(overlay,right_pts,color=[0,0,255],isClosed=False,thickness=30)\n",
    "     \n",
    "    # Unwarp our copy of the bird's eye view. This will automatically unwarp all\n",
    "    # the drawing we did above.\n",
    "    unwarp = warp(overlay,Minv)\n",
    "    \n",
    "    # Overlay drawings on top of the frame image.\n",
    "    final = cv2.addWeighted(undistorted,1.0,unwarp,0.3,0.0)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video processed-project_video.mp4\n",
      "[MoviePy] Writing video processed-project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [09:23<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: processed-project_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "in_clip = VideoFileClip('project_video.mp4')\n",
    "\n",
    "out_filename = 'processed-project_video.mp4'\n",
    "out_clip = in_clip.fl_image(draw_lanes)\n",
    "\n",
    "out_clip.write_videofile(out_filename,audio=False)\n",
    "\n",
    "clr_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code:\n",
    "Following cells contain functions for testing diffrent stages of the pipeline. They can be run by enabling the **__DEBUG__** flag at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test distortion correction.\n",
    "def test_undistortion(img_path):\n",
    "    test_img = imgread_rgb(img_path)\n",
    "    undistorted = cv2.undistort(test_img,cameraMatrix,distCoeffs)\n",
    "    plot_many([test_img,undistorted],['orginal','udistorted'],[1,2])\n",
    "    \n",
    "if __DEBUG__ == True:\n",
    "    test_undistortion('camera_cal/calibration1.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visulaize individual and combined sobel masks for all test images.\n",
    "def visualize_candidate_masks(img_paths,group=0):\n",
    "\n",
    "    s_mask_fn = get_channel_mask_fn('s')\n",
    "    h_mask_fn = get_channel_mask_fn('h')\n",
    "    l_mask_fn = get_channel_mask_fn('l')\n",
    "\n",
    "    for path in img_paths:\n",
    "        img_rgb = imgread_rgb(path)\n",
    "\n",
    "        [x_mask,y_mask,mag_mask,ang_mask] = get_sobel_masks(img_rgb,threshold_params=get_thresholds())\n",
    "        x_y_mask = x_mask & y_mask\n",
    "        mag_ang_mask = mag_mask & ang_mask\n",
    "\n",
    "        all_mask1 = x_y_mask | mag_ang_mask\n",
    "\n",
    "        s_mask = s_mask_fn(img_rgb,thresh=(90,255))\n",
    "        l_mask = l_mask_fn(img_rgb,thresh=(0,20))\n",
    "        \n",
    "        w_mask = ~s_mask_fn(img_rgb,thresh=(170,100)) & ~l_mask_fn(img_rgb,thresh=(0,80))\n",
    "\n",
    "        x_s_mask = x_mask | s_mask\n",
    "        y_s_mask = y_mask & s_mask\n",
    "        x_y_s_mask = x_s_mask & y_s_mask\n",
    "\n",
    "        mag_s_mask = mag_mask | s_mask\n",
    "        ang_s_mask = ang_mask | s_mask\n",
    "        mag_ang_s_mask = mag_s_mask | ang_s_mask\n",
    "\n",
    "        all_mask2 = x_y_s_mask | mag_ang_s_mask\n",
    "\n",
    "    \n",
    "        if group == 0:\n",
    "            plot_many([img_rgb,x_mask,y_mask,x_y_mask,\n",
    "                       mag_mask,ang_mask,mag_ang_mask,all_mask1,\n",
    "                       s_mask,x_s_mask,y_s_mask,x_y_s_mask,\n",
    "                       mag_s_mask,ang_s_mask,mag_ang_s_mask,all_mask2],\n",
    "                      ['original','x','y','(x&y)',\n",
    "                       'magnitude','angle','(mag&ang)','All1',\n",
    "                       's','(s|x)','(s|y)','(s|x) & (s|y)', \n",
    "                       '(s|mag)','(s&ang)','((s|mag) |(s&ang))','All2'],\n",
    "                      [4,4],figsize=(24,18))\n",
    "            \n",
    "        elif group == 1:\n",
    "\n",
    "            plot_many([img_rgb,x_s_mask,mag_s_mask,\n",
    "                       ang_s_mask,(x_s_mask|mag_s_mask|ang_s_mask),((s_mask&x_mask)|(s_mask&y_mask)|mag_mask|s_mask&ang_mask)],\n",
    "                      ['original','(s|x)','(s|mag)',\n",
    "                       '(s&ang)','(s|x)| (s|mag)|(s&ang)','((s&x)|(s&y))|mag|(s&ang)'],\n",
    "                      [2,3])\n",
    "            \n",
    "        elif group == 2:\n",
    "            plot_many([img_rgb,mag_ang_s_mask],\n",
    "                      ['original','(s|mag)|(s&ang)'],\n",
    "                      [1,2])\n",
    "            \n",
    "        elif group == 3:\n",
    "            plot_many([img_rgb,x_mask,y_mask,mag_mask,\n",
    "                       ang_mask,s_mask,~l_mask,get_lane_mask(img_rgb,get_thresholds())],\n",
    "                      [path,'x','y','mag',\n",
    "                       'ang','s','~l','lane'],\n",
    "                      [2,4])\n",
    "            \n",
    "        elif group == 4:\n",
    "            plot_many([img_rgb,x_mask&s_mask,mag_mask&ang_mask],\n",
    "                      [path,'x&s','mag & ang'],\n",
    "                      [1,3])\n",
    "\n",
    "if __DEBUG__ == True:\n",
    "    visualize_candidate_masks(glob('bad_frames1/*.png')[:3],4)\n",
    "    visualize_candidate_masks(glob('test_images/*.jpg'),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Setup and test perspective transform.\n",
    "def test_perspective_transform(ref_img_path,test_img_path,src_points,dst_points):\n",
    "    # Load image of straight lane lines and apply undistortion.\n",
    "    img_straight_rgb = imgread_rgb(ref_img_path)\n",
    "    img_straight_rgb = cv2.undistort(img_straight_rgb,cameraMatrix,distCoeffs)\n",
    "\n",
    "\n",
    "    img_straight_rgb_warped = warp(img_straight_rgb,M)\n",
    "\n",
    "    # Test on train image\n",
    "    plot_many([overlay_polygon(img_straight_rgb,src_points),overlay_polygon(img_straight_rgb_warped,dst_points)],\n",
    "              ['original','warped'],\n",
    "              [1,2])\n",
    "\n",
    "    # Test on curved lane image\n",
    "    curved_image = imgread_rgb(test_img_path)\n",
    "    curved_image = cv2.undistort(curved_image,cameraMatrix,distCoeffs)\n",
    "    transformed_image = warp(curved_image,M)\n",
    "    plot_many([curved_image,transformed_image],['original','warped'],[1,2])\n",
    "    \n",
    "if __DEBUG__ == True:   \n",
    "    test_perspective_transform(perspective_ref_img_path,'test_images/test5.jpg',\n",
    "                               perspective_src_points,perspective_dst_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_lane_detection(img_rgb_path):\n",
    "    test_img_rgb = imgread_rgb(img_rgb_path)\n",
    "    \n",
    "    undistort_rgb = cv2.undistort(test_img_rgb,cameraMatrix,distCoeffs)\n",
    "    binary_image = get_lane_mask(undistort_rgb,get_thresholds())\n",
    "    \n",
    "    perspective_corrected = warp(binary_image,M) \n",
    "    \n",
    "    left_lane_info,right_lane_info = find_lanes(perspective_corrected)\n",
    "    \n",
    "    left_lane_windows = left_lane_info[0]\n",
    "    right_lane_windows = right_lane_info[0]\n",
    "    \n",
    "    left_lane_x,left_lane_y = left_lane_info[1]\n",
    "    right_lane_x, right_lane_y = right_lane_info[1]\n",
    "    \n",
    "    left_poly = fit_poly_to_lane(left_lane_x,left_lane_y)\n",
    "    right_poly = fit_poly_to_lane(right_lane_x,right_lane_y)\n",
    "    \n",
    "    ys = np.array(range(perspective_corrected.shape[0]),dtype=np.int32)\n",
    "    xs_left  = eval_qudratic(left_poly,ys)\n",
    "    xs_right = eval_qudratic(right_poly,ys)\n",
    "  \n",
    "    search_area_img = np.dstack((perspective_corrected,perspective_corrected,perspective_corrected)) * 255\n",
    "    \n",
    "    for window in left_lane_windows:\n",
    "        cv2.rectangle(search_area_img,window[0],window[1],color=[255,0,0],thickness=5)\n",
    "    \n",
    "    for window in right_lane_windows:\n",
    "        cv2.rectangle(search_area_img,window[0],window[1],color=[255,0,0],thickness=5)\n",
    "     \n",
    "    left_points = [(x,y) for (x,y) in zip(xs_left,ys)]\n",
    "    right_points  = [(x,y) for (x,y) in zip(xs_right,ys)]\n",
    "    all_points = [pt for pt in left_points]\n",
    "    all_points.extend([pt for pt in reversed(right_points)])\n",
    "       \n",
    "    cv2.fillPoly(search_area_img,np.array([all_points],dtype = np.int32),[255,255,0])\n",
    "    draw_polygon(search_area_img,left_points,color=[0,255,0],isClosed=False,thickness=10)\n",
    "    draw_polygon(search_area_img,right_points,color=[0,0,255],isClosed=False,thickness=10)\n",
    "    \n",
    "    # Unwarp\n",
    "    unwarp = warp(search_area_img,Minv)\n",
    "    final = cv2.addWeighted(undistort_rgb,0.5,unwarp,1.0,0.0)\n",
    "               \n",
    "    plot_many([test_img_rgb,undistort_rgb,binary_image,perspective_corrected,search_area_img,final],\n",
    "          ['input','undistoted','lane masks','perpective corrected mask','search windows','final'],\n",
    "          [2,3],\n",
    "          [None,None,'gray','gray',None,None]) \n",
    "    \n",
    "if __DEBUG__ == True:\n",
    "    for path in glob('test_images/*.jpg'):\n",
    "        test_lane_detection(path)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
